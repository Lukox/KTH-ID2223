{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCcEEKyHGU5j"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install keras==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import pickle"
      ],
      "metadata": {
        "id": "AwLPm459G1L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMXy95tvG2Vi",
        "outputId": "ab216bfa-3792-40c2-d2d5-cb85616403bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Raw Data"
      ],
      "metadata": {
        "id": "7Jws7S1KOPEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ML/dataset.pkl\", 'rb') as file:\n",
        "  data = pickle.load(file)"
      ],
      "metadata": {
        "id": "WhaeRqlSK5i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_blue = []\n",
        "X_red = []\n",
        "y = []\n",
        "team_indicator_blue = []\n",
        "team_indicator_red = []"
      ],
      "metadata": {
        "id": "xUOfNC0iP_87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10001):\n",
        "    blue_side_features = []\n",
        "    red_side_features = []\n",
        "    blue_side_indicator = [0] * 5  # 0 for blue side\n",
        "    red_side_indicator = [1] * 5   # 1 for red side\n",
        "\n",
        "    matchData = data[i]\n",
        "    for i, participant in enumerate(matchData):\n",
        "        # Extract features\n",
        "        #print(participant)\n",
        "        champion_id = participant[\"championId\"]\n",
        "\n",
        "        # Decide which team (blue or red) the participant belongs to\n",
        "        if i < 5:\n",
        "            blue_side_features.append(champion_id)\n",
        "        else:\n",
        "            red_side_features.append(champion_id)\n",
        "\n",
        "    y.append(1 if participant[\"win\"] and i >= 5 else 0)\n",
        "    X_blue.append(blue_side_features)\n",
        "    X_red.append(red_side_features)\n",
        "    team_indicator_blue.append(blue_side_indicator)\n",
        "    team_indicator_red.append(red_side_indicator)"
      ],
      "metadata": {
        "id": "S4If9m3uP2NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_blue = np.array(X_blue)\n",
        "X_red = np.array(X_red)\n",
        "y = np.array(y)\n",
        "\n",
        "# Create a OneHotEncoder\n",
        "encoder = OneHotEncoder(categories='auto', sparse=False)\n",
        "\n",
        "# Fit and transform champion IDs for both blue and red teams\n",
        "X_blue_encoded = encoder.fit_transform(X_blue)\n",
        "X_red_encoded = encoder.fit_transform(X_red)\n",
        "\n",
        "# Concatenate blue and red features along the last axis\n",
        "X_encoded = np.concatenate((X_blue_encoded, X_red_encoded), axis=-1)\n",
        "\n",
        "# Concatenate team indicators\n",
        "team_indicator_blue = np.array(team_indicator_blue)\n",
        "team_indicator_red = np.array(team_indicator_red)\n",
        "team_indicators = np.concatenate((team_indicator_blue, team_indicator_red), axis=-1)\n",
        "\n",
        "# Combine features and team indicators\n",
        "X_combined = np.concatenate((X_encoded, team_indicators), axis=-1)"
      ],
      "metadata": {
        "id": "D_Xqxb6_LIZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=21)\n",
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(200, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "ZAigH7EbLo3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For raw data only, the highest accuracy we were able to get was 54%"
      ],
      "metadata": {
        "id": "75PItTx5Rxi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Engineered Features"
      ],
      "metadata": {
        "id": "P6UiE_q6OSSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ML/data.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "bi-k8mQJG2zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import X_OK\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df.drop(\"teamWin\", axis=1)\n",
        "\n",
        "y = df[\"teamWin\"]"
      ],
      "metadata": {
        "id": "xbkf2v9PHE_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def create_model(hidden_units=(16,), activation='relu', optimizer='adam', dropout_rate=0.0, weight_decay=0.0):\n",
        "    model = Sequential()\n",
        "    for units in hidden_units:\n",
        "        model.add(Dense(units=units, activation=activation, kernel_regularizer='l2'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a KerasClassifier for use with scikit-learn GridSearchCV\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Define hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'hidden_units': [[50], [20, 10, 6], [200, 100, 60], [64, 32, 16, 8]],\n",
        "    'activation': ['relu', 'sigmoid'],\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'dropout_rate': [0.0, 0.2, 0.4],\n",
        "    'weight_decay': [0.0, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to perform the search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding accuracy\n",
        "print(\"Best Parameters: \", grid_result.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(grid_result.best_score_ * 100))\n",
        "\n",
        "# Evaluate the model on the test set with the best parameters\n",
        "best_model = grid_result.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "id": "Ea6ZA2G0SB7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 300, 500],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
        "    'max_leaf_nodes': [None, 10, 20, 30],\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Perform randomized search\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_model, param_distributions=param_dist, scoring='accuracy', n_iter=100, cv=3, verbose=1, random_state=21\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Summarize results\n",
        "print(f\"Best accuracy: {random_search.best_score_} using {random_search.best_params_}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_rf_model = random_search.best_estimator_\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "Gg9MnOBp6EEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
        "\n",
        "# Create and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=21)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "yrpj5I6iHHQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90959fa6-fe33-4b7a-da65-59126fd7a3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 68.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_folds = 10  # You can adjust this based on your preference\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Create a neural network model\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize an empty list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, test_index in stratified_kfold.split(X_scaled, y):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create and train the model\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred_proba = model.predict(X_test)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Calculate and store the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Print the accuracy scores for each fold\n",
        "for i, accuracy in enumerate(accuracy_scores, start=1):\n",
        "    print(f\"Fold {i} accuracy: {accuracy}\")\n",
        "\n",
        "# Print the mean and standard deviation of the accuracy scores\n",
        "print(f\"Mean accuracy: {np.mean(accuracy_scores)}\")\n",
        "print(f\"Standard deviation: {np.std(accuracy_scores)}\")\n"
      ],
      "metadata": {
        "id": "VekEbcD3oth5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the best model to drive"
      ],
      "metadata": {
        "id": "MBcwHAx8FLyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from google.colab import drive\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Best parameters from your grid search\n",
        "best_params = {'activation': 'relu', 'dropout_rate': 0.4, 'hidden_units': [50], 'optimizer': 'rmsprop', 'weight_decay': 0.0001}\n",
        "\n",
        "# Create the model with the best parameters\n",
        "best_model = Sequential()\n",
        "for units in best_params['hidden_units']:\n",
        "    best_model.add(Dense(units=units, activation=best_params['activation'], kernel_regularizer='l2'))\n",
        "    best_model.add(Dropout(best_params['dropout_rate']))\n",
        "best_model.add(Dense(units=1, activation='sigmoid'))\n",
        "best_model.compile(loss='binary_crossentropy', optimizer=best_params['optimizer'], metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the entire training set\n",
        "best_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Save the best model to Google Drive\n",
        "best_model.save(\"/content/drive/My Drive/ML/model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred.round())\n",
        "print(\"Test Accuracy with Best Parameters: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "id": "_OUibI-RJ6jH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}